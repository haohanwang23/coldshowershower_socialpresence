{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cvxEDA\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "\n",
    "import pylab as pl\n",
    "from scipy.stats import ttest_1samp, wilcoxon, ttest_ind, mannwhitneyu\n",
    "from sklearn.preprocessing import normalize\n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (10, 8),\n",
    "         'axes.labelsize': 'large',\n",
    "         'axes.titlesize':'large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large'}\n",
    "pl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/group1/EDA2.csv',\n",
       " 'data/group1/EDA1.csv',\n",
       " 'data/group1/EDA5.csv',\n",
       " 'data/group1/EDA6.csv',\n",
       " 'data/group1/EDA4.csv',\n",
       " 'data/group1/EDA3.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = 'data/group1'\n",
    "path2 = 'data/group2'\n",
    "# frequency = df.iloc[1].values\n",
    "filenames = [join(path1,f) for f in listdir(path1) if isfile(join(path1, f))]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_names(path):\n",
    "    filenames = [join(path,f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    df = pd.read_csv(filename , header= None)\n",
    "    df.columns = ['eda']\n",
    "    frequency = df.iloc[1].values\n",
    "    df_init_time = datetime.datetime(2018, np.random.choice(range(3,5),1), \n",
    "                                     np.random.choice(range(1,30),1), \n",
    "                                     7, 0,0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    time_series = pd.date_range(start=df_init_time, periods=len(df), \n",
    "                          freq=str(1/int(frequency))+'S')\n",
    "    df = df.set_index(time_series, drop =True)\n",
    "    df = df[3:]\n",
    "    df= df.between_time('7:00', '9:00')\n",
    "#     df['eda_norm'] = (df.eda - df.eda.min()) / (df.eda.max() - df.eda.min())\n",
    "    df['std_eda'] = (df.eda - df.eda.mean()) / (df.eda.std())\n",
    "    df = df.round(3)\n",
    "# #     eda_std = []\n",
    "# #     eda_std.append(df['eda_std'])\n",
    "#     def quantile(df,quant):\n",
    "        \n",
    "# #         mean = []\n",
    "#         eda_mean = np.mean(df.eda_std)\n",
    "#         eda_quan = df.eda_std.quantile(quant)\n",
    "#         count = sum(i > eda_quan for i in df.eda)\n",
    "#         max_scr = max(df.eda_std)\n",
    "# #         plt.figure(figsize=(15,6))\n",
    "# #         plt.plot(df['eda'],color ='mediumaquamarine')\n",
    "# #         plt.axhline(y = eda_mean, color = 'lightsalmon', linestyle = '--')\n",
    "# #         plt.axhline(y = eda_quan, color = 'coral', linestyle = '--')\n",
    "#         return count,eda_mean,max_scr\n",
    "   \n",
    "#     if quant:\n",
    "#         return (df,quantile(df,quant))\n",
    "#     else:\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def quantile(df,quant):\n",
    "#         eda_mean =[]\n",
    "#         eda_quan =[]\n",
    "#         count = []\n",
    "#         max_scr =[]\n",
    "#         for col in df.columns: \n",
    "            eda_mean.append(np.mean(df.col))\n",
    "            eda_quan=df.col.quantile(quant))\n",
    "            count.append(sum(i > eda_quan for i in df.col))\n",
    "            max_scr.append(max(df.eda_std))\n",
    "            prop = count/len(df)\n",
    "    #         plt.figure(figsize=(15,6))\n",
    "    #         plt.plot(df['eda'],color ='mediumaquamarine')\n",
    "    #         plt.axhline(y = eda_mean, color = 'lightsalmon', linestyle = '--')\n",
    "    #         plt.axhline(y = eda_quan, color = 'coral', linestyle = '--')\n",
    "        return prop,eda_mean,max_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df(df1,df2,df3,df4,df5,df6):\n",
    "#     std_eda = []\n",
    "#     group_eda = pd.DataFrame({'person1':df1.std_eda, \n",
    "#                               'person2':df2.std_eda,\n",
    "#                               'person3':df3.std_eda,\n",
    "#                               'person4':df4.std_eda,\n",
    "#                               'person5':df5.std_eda,\n",
    "#                               'person6':df6.std_eda})\n",
    "# pd.concat([s1, s2], keys=['s1', 's2'],\n",
    "# ...           names=['Series name', 'Row ID'])\n",
    "    group_eda = pd.concat([df1.std_eda), df2.std_eda,df3.std_eda,\n",
    "                         df4.std_eda,df5.std_eda,df6.std_eda],axis=1)\n",
    "    group_eda.columns = ['person1','person2','person3','person4','person5','person6']\n",
    "# group_count = pd.DataFrame([df1.std_eda, df2.std_eda,df3.std_eda,\n",
    "#                          df4.std_eda,df5.std_eda,df6.std_eda],\n",
    "#                          columns = ['person1','person2','person3',\n",
    "#                                     'person4','person5','person6'])\n",
    "#     group_mean = pd.DataFrame([df1.std_eda, df2.std_eda,df3.std_eda,\n",
    "#                          df4.std_eda,df5.std_eda,df6.std_eda],\n",
    "#                          columns = ['person1','person2','person3',\n",
    "#                                     'person4','person5','person6'])\n",
    "#     group_max = pd.DataFrame([df1.std_eda, df2.std_eda,df3.std_eda,\n",
    "#                          df4.std_eda,df5.std_eda,df6.std_eda],\n",
    "#                          columns = ['person1','person2','person3',\n",
    "#                                     'person4','person5','person6'])\n",
    "    return group_eda\n",
    "#     stats.f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
    "#     scipy.stats.ttest_ind(a, b, axis=0, equal_var=True,\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(group1, group2):\n",
    "#      stats.f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
    "   return scipy.stats.ttest_ind(group1,group2, axis=0, equal_var=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvx_eda(df):\n",
    "    y = np.asarray(df.std_eda)\n",
    "#     yn = (y - y.mean()) / y.std()\n",
    "    Fs = 4.\n",
    "    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1./Fs)\n",
    "    return y,r\n",
    "\n",
    "def plot(yn,r):\n",
    "    # pl.rcParams['figure.figsize'] = (30,20)\n",
    "    tm = pl.arange(1., len(y)+1.) / Fs\n",
    "\n",
    "#     pl.hold(True)\n",
    "    pl.plot(tm, yn,alpha = 0.6,color= 'mediumaquamarine')\n",
    "\n",
    "    pl.plot(tm, r,alpha = 0.5,color = 'lightsalmon')\n",
    "# pl.plot(tm1, p1,alpha = 0.6)\n",
    "#     pl.plot(tm, t,alpha = 0.6, color = 'mediumpurple')\n",
    "\n",
    "\n",
    "    pl.title('cvxEDA Deconvolution Analysis on EDA ')\n",
    "    pl.legend(['SC Z-score','Phasic Component'])\n",
    "#     plt.savefig('.png', transparent=True)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eda</th>\n",
       "      <th>std_eda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-13 07:00:00.750</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13 07:00:01.000</th>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13 07:00:01.250</th>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13 07:00:01.500</th>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13 07:00:01.750</th>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eda  std_eda\n",
       "2018-04-13 07:00:00.750  0.027   -0.894\n",
       "2018-04-13 07:00:01.000  0.060   -0.736\n",
       "2018-04-13 07:00:01.250  0.060   -0.736\n",
       "2018-04-13 07:00:01.500  0.061   -0.729\n",
       "2018-04-13 07:00:01.750  0.063   -0.723"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_1,df1_2,df1_3,df1_4,df1_5,df1_6 =  [import_data(filepath) \n",
    "                                        for filepath in file_names(path1)]\n",
    "df2_1,df2_2,df2_3,df2_4,df2_5,df2_6 =  [import_data(filepath) \n",
    "                                        for filepath in file_names(path2)]\n",
    "\n",
    "\n",
    "df1_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6754b1229cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgroup1_eda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgroup2_eda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgroup1_eda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# group1_eda.dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-7c15af7b0d58>\u001b[0m in \u001b[0;36mconstruct_df\u001b[0;34m(df1, df2, df3, df4, df5, df6)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# pd.concat([s1, s2], keys=['s1', 's2'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ...           names=['Series name', 'Row ID'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgroup_eda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'std_eda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgroup_eda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'person1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'person2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'person3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'person4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'person5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'person6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# group_count = pd.DataFrame([df1.std_eda, df2.std_eda,df3.std_eda,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concat_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_concat_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             concat_axis = _make_concat_multiindex(indexes, self.keys,\n\u001b[0;32m--> 514\u001b[0;31m                                                   self.levels, self.names)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_make_concat_multiindex\u001b[0;34m(indexes, keys, levels, names)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mhlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3244\u001b[0;31m             raise InvalidIndexError('Reindexing only valid with uniquely'\n\u001b[0m\u001b[1;32m   3245\u001b[0m                                     ' valued Index objects')\n\u001b[1;32m   3246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "group1_eda = construct_df(df1_1,df1_2,df1_3,df1_4,df1_5,df1_6)\n",
    "group2_eda = construct_df(df2_1,df2_2,df2_3,df2_4,df2_5,df2_6)\n",
    "\n",
    "group1_eda.person2\n",
    "# group1_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest(group1,group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df1_1,count1_1,mean1_1,max_scr1_1),(df1_2,count1_2,mean1_2,max_scr1_2),(df1_3,count1_3,mean1_3,max_scr1_3),(df1_4,count1_4,mean1_4,max_scr1_4),(df1_5,count1_5,mean1_5,max_scr1_5),(df1_6,count1_6,mean1_6,max_scr1_6) = [import_data(filepath,0.75) for filepath in file_names(path1)]\n",
    "# (df2_1,count2_1,mean2_1,max_scr2_1),(df2_2,count2_2,mean2_2,max_scr2_2),(df2_3,count2_3,mean2_3,max_scr2_3),S(df2_4,count2_4,mean2_4,max_scr2_4),(df2_5,count2_5,mean2_5,max_scr2_5),(df2_6,count2_6,mean2_6,max_scr2_6) =[import_data(filepath,0.75) for filepath in file_names(path2)]\n",
    "# group1 =[]\n",
    "# group2 =[]\n",
    "# group1.extend((count1_1,count1_2,count1_3,count1_4,count1_5,count1_6))\n",
    "# group2.extend((count1_1,count1_2,count1_3,count1_4,count1_5,count1_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df1_1,count1_1,mean1_1,max_scr1_1),(df1_2,count1_2,mean1_2,max_scr1_2),(df1_3,count1_3,mean1_3,max_scr1_3),\\\n",
    "# (df1_4,count1_4,mean1_4,max_scr1_4),(df1_5,count1_5,mean1_5,max_scr1_5),\\\n",
    "# (df1_6,count1_6,mean1_6,max_scr1_6) = [import_data(filepath,0.75) \n",
    "#                                                     for filepath in file_names(path1)]\n",
    "# (df2_1,count2_1,mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cvx_eda(df):\n",
    "#     y = np.asarray(df.eda)\n",
    "#     yn1 = (y - y.mean()) / y.std()\n",
    "#     Fs = 4.\n",
    "#     [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1./Fs)\n",
    "\n",
    "#     # pl.rcParams['figure.figsize'] = (30,20)\n",
    "#     tm = pl.arange(1., len(y)+1.) / Fs\n",
    "    \n",
    "#     pl.hold(True)\n",
    "#     pl.plot(tm, yn,alpha = 0.6,color= 'mediumaquamarine')\n",
    "\n",
    "#     pl.plot(tm, r,alpha = 0.5,color = 'lightsalmon')\n",
    "# # pl.plot(tm1, p1,alpha = 0.6)\n",
    "#     pl.plot(tm, t,alpha = 0.6, color = 'mediumpurple')\n",
    "\n",
    "\n",
    "#     pl.title('cvxEDA Deconvolution Analysis on EDA ')\n",
    "#     pl.legend(['SC Z-score','Phasic Component','Tonic Component'])\n",
    "# #     plt.savefig('.png', transparent=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantile(df):\n",
    "#     quan_75 = []\n",
    "#     eda_mean = np.mean(df.eda_norm)\n",
    "#     eda_75 = df.eda_norm.quantile(0.75)\n",
    "#     quan_75.append(sum(i > eda_75 for i in df.eda_norm))\n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(df['eda_norm'],color ='mediumaquamarine')\n",
    "#     plt.axhline(y = eda_mean, color = 'lightsalmon', linestyle = '--')\n",
    "#     plt.axhline(y = eda_75, color = 'coral', linestyle = '--')\n",
    "# #     df.plot(df.eda_norm)\n",
    "#     return quan_75\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_eda_7 = pd.read_csv('../data/day_7/EDA.csv' , header= None)\n",
    "fl_eda_7.columns  = ['eda']\n",
    "fl_eda_freq_7 = fl_eda_7.iloc[1].values\n",
    "print(len(fl_eda_7))\n",
    "print('freq: ', fl_eda_freq_7)\n",
    "fl_eda_7.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl_init_time_7 = datetime.datetime.fromtimestamp(fl_eda_7.iloc[0]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "fl_init_time_7 = datetime.datetime(2018, 4, 16, 7, 0,0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "fl_init_time_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_time_eda_7 = pd.date_range(start=fl_init_time_7, periods=len(fl_eda_7), \n",
    "                              freq=str(1/int(fl_eda_freq_7))+'S')\n",
    "fl_time_eda_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_eda_7 = fl_eda_7.set_index(fl_time_eda_7, drop =True)\n",
    "fl_eda_7 = fl_eda_7[3:]\n",
    "# fl_eda_7= pd.date_range('07:00:00', '09:00:00')\n",
    "fl_eda_7 = fl_eda_7.dropna()\n",
    "print(len(fl_eda_7))\n",
    "fl_eda_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_eda_7['eda_norm'] = (fl_eda_7.eda - fl_eda_7.eda.min()) / (fl_eda_7.eda.max() - fl_eda_7.eda.min())\n",
    "fl_eda_7.head()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the frequency above 75% quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_75 = np.mean(fl_eda_7.eda_norm.quantile(0.75))\n",
    "sum(i > eda_75 for i in fl_eda_7.eda_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axvline(x = '2018-07-03 15:20:50.000',color = 'mediumaquamarine',linestyle='--')\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(fl_eda_7['eda_norm'],color ='mediumaquamarine')\n",
    "\n",
    "# for (idx,data_point, presence, label) in tags_7.itertuples():\n",
    "# #     print(data_point)\n",
    "#     plt.axvline(x=data_point,color = 'lightsalmon', linestyle='--')\n",
    "#     plt.text(data_point,0.05, s=label, horizontalalignment='center', verticalalignment='center',\n",
    "#             fontsize=15)\n",
    "# # # plt.axvline(x = tags_2.tagged_time[5],color = 'c',linestyle='--')\n",
    "# plt.figtext(.5,.9,'Day 7 Social presence and stress response of cold shower - EDA ',\n",
    "#             fontsize=20, ha='center')\n",
    "# plt.legend(['EDA_day3'],loc=2,fontsize='medium')\n",
    "\n",
    "\n",
    "print(eda_mean)\n",
    "plt.axhline(y = eda_mean, color = 'lightsalmon', linestyle = '--')\n",
    "# plt.savefig('black-eda.png', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
